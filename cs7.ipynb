{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_project.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              x0        x1         x2         x3        x4         x5  \\\n",
      "0      -0.166563 -3.961588   4.621113   2.481908 -1.800135   0.804684   \n",
      "1      -0.149894 -0.585676  27.839856   4.152333  6.426802  -2.426943   \n",
      "2      -0.321707 -1.429819  12.251561   6.586874 -5.304647 -11.311090   \n",
      "3      -0.245594  5.076677 -24.149632   3.637307  6.505811   2.290224   \n",
      "4      -0.273366  0.306326 -11.352593   1.676758  2.928441  -0.616824   \n",
      "...          ...       ...        ...        ...       ...        ...   \n",
      "159995 -0.487024 -4.270269   0.417395  -1.992423  1.757552  -1.167819   \n",
      "159996  0.825477  4.804368  22.161535  11.371303  1.715901   6.990759   \n",
      "159997 -0.802489  5.362696   7.243419  -7.496074  2.295250  -2.756067   \n",
      "159998  0.339237  7.609895   5.368414  -2.825481  4.046102  15.322603   \n",
      "159999 -0.296748 -0.412773 -10.911407  -5.633629 -4.028154  15.939428   \n",
      "\n",
      "               x6         x7         x8        x9  ...        x41       x42  \\\n",
      "0        6.718751 -14.789997  -1.040673 -4.204950  ...  -1.497117  5.414063   \n",
      "1       40.477058  -6.725709   0.896421  0.330165  ...  36.292790  4.490915   \n",
      "2       17.812850  11.060572   5.325880 -2.632984  ...  -0.368491  9.088864   \n",
      "3      -35.111751 -18.913592  -0.337041 -5.568076  ...  15.691546 -7.467775   \n",
      "4      -16.505817  27.532281   1.199715 -4.309105  ... -13.911297 -5.229937   \n",
      "...           ...        ...        ...       ...  ...        ...       ...   \n",
      "159995   0.606860  41.084463  -1.923188 -2.374213  ...  -9.390451  8.096802   \n",
      "159996  32.221207 -12.278038  -3.861086  6.715126  ...  12.803189  0.841446   \n",
      "159997  10.531388  42.515821   1.420984  6.788916  ...  -0.346570 -0.144098   \n",
      "159998   7.805271 -10.233054   2.609986  4.251127  ...  -0.307656 -0.601145   \n",
      "159999 -15.864365 -46.388192  18.339472 -4.575499  ...  27.837473  1.392395   \n",
      "\n",
      "             x43       x44       x45        x46       x47       x48  \\\n",
      "0      -2.325655  1.674827 -0.264332  60.781427 -7.689696  0.151589   \n",
      "1       0.762561  6.526662  1.007927  15.805696 -4.896678 -0.320283   \n",
      "2      -0.689886 -2.731118  0.754200  30.856417 -7.428573 -2.090804   \n",
      "3       2.940789 -6.424112  0.419776 -72.424569  5.361375  1.806070   \n",
      "4       1.783928  3.957801 -0.096988 -14.085435 -0.208351 -0.894942   \n",
      "...          ...       ...       ...        ...       ...       ...   \n",
      "159995 -0.875131 -1.413787 -0.363968  15.339392  4.364205 -3.831489   \n",
      "159996 -0.682177 -5.047677 -0.017898   0.780130  6.387266 -1.374742   \n",
      "159997  0.738298  7.241041  0.215347 -12.155249  3.265263  1.230963   \n",
      "159998 -3.443112  0.549931  0.206728   5.081980  1.701462 -0.279619   \n",
      "159999  0.893555 -1.848590 -0.423982 -17.379380  5.916490 -2.767444   \n",
      "\n",
      "              x49  y  \n",
      "0       -8.040166  0  \n",
      "1       16.719974  0  \n",
      "2       -7.869421  0  \n",
      "3       -7.670847  0  \n",
      "4       15.724742  1  \n",
      "...           ... ..  \n",
      "159995  28.389858  1  \n",
      "159996  -1.623952  0  \n",
      "159997   3.335471  1  \n",
      "159998  -1.986424  0  \n",
      "159999  15.547557  1  \n",
      "\n",
      "[160000 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0     float64\n",
       "x1     float64\n",
       "x2     float64\n",
       "x3     float64\n",
       "x4     float64\n",
       "x5     float64\n",
       "x6     float64\n",
       "x7     float64\n",
       "x8     float64\n",
       "x9     float64\n",
       "x10    float64\n",
       "x11    float64\n",
       "x12    float64\n",
       "x13    float64\n",
       "x14    float64\n",
       "x15    float64\n",
       "x16    float64\n",
       "x17    float64\n",
       "x18    float64\n",
       "x19    float64\n",
       "x20    float64\n",
       "x21    float64\n",
       "x22    float64\n",
       "x23    float64\n",
       "x24     object\n",
       "x25    float64\n",
       "x26    float64\n",
       "x27    float64\n",
       "x28    float64\n",
       "x29     object\n",
       "x30     object\n",
       "x31    float64\n",
       "x32     object\n",
       "x33    float64\n",
       "x34    float64\n",
       "x35    float64\n",
       "x36    float64\n",
       "x37     object\n",
       "x38    float64\n",
       "x39    float64\n",
       "x40    float64\n",
       "x41    float64\n",
       "x42    float64\n",
       "x43    float64\n",
       "x44    float64\n",
       "x45    float64\n",
       "x46    float64\n",
       "x47    float64\n",
       "x48    float64\n",
       "x49    float64\n",
       "y        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0     26\n",
      "x1     25\n",
      "x2     38\n",
      "x3     37\n",
      "x4     26\n",
      "x5     37\n",
      "x6     26\n",
      "x7     27\n",
      "x8     21\n",
      "x9     30\n",
      "x10    43\n",
      "x11    30\n",
      "x12    36\n",
      "x13    31\n",
      "x14    34\n",
      "x15    35\n",
      "x16    26\n",
      "x17    27\n",
      "x18    40\n",
      "x19    35\n",
      "x20    38\n",
      "x21    29\n",
      "x22    27\n",
      "x23    47\n",
      "x24    28\n",
      "x25    22\n",
      "x26    36\n",
      "x27    30\n",
      "x28    35\n",
      "x29    30\n",
      "x30    30\n",
      "x31    39\n",
      "x32    31\n",
      "x33    41\n",
      "x34    41\n",
      "x35    30\n",
      "x36    27\n",
      "x37    23\n",
      "x38    31\n",
      "x39    23\n",
      "x40    36\n",
      "x41    40\n",
      "x42    26\n",
      "x43    37\n",
      "x44    40\n",
      "x45    29\n",
      "x46    31\n",
      "x47    37\n",
      "x48    32\n",
      "x49    32\n",
      "y       0\n",
      "dtype: int64\n",
      "0    95803\n",
      "1    64197\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_na = df.isna().sum()\n",
    "print(count_na)\n",
    "class_counts = df['y'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling the % in 'x32' by stripping the % and converting to float, then divide by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0000\n",
       "1        -0.0002\n",
       "2        -0.0001\n",
       "3         0.0001\n",
       "4         0.0001\n",
       "           ...  \n",
       "159995    0.0000\n",
       "159996   -0.0001\n",
       "159997   -0.0000\n",
       "159998   -0.0002\n",
       "159999    0.0002\n",
       "Name: x32, Length: 160000, dtype: float64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x32'] = df['x32'].str.replace('%', '')\n",
    "df['x32'] = pd.to_numeric(df['x32']) / 100\n",
    "df['x32']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling column 'x37' by stripping the $ and converting it to a float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\AppData\\Local\\Temp\\ipykernel_30712\\3516218164.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['x37'] = df['x37'].str.replace('$', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         1313.96\n",
       "1         1962.78\n",
       "2          430.47\n",
       "3        -2366.29\n",
       "4         -620.66\n",
       "           ...   \n",
       "159995    -891.96\n",
       "159996    1588.65\n",
       "159997     687.46\n",
       "159998     439.21\n",
       "159999   -1229.34\n",
       "Name: x37, Length: 160000, dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x37'] = df['x37'].str.replace('$', '')\n",
    "df['x37'] = pd.to_numeric(df['x37'])\n",
    "df['x37']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing all of the missing data with either mean imputation for numerical or most frequent for category imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [f\"x{i}\" for i in range(50) if i not in [24, 29, 30]]\n",
    "cat_cols = [\"x24\", \"x29\", \"x30\"]\n",
    "#copy the target before doing the transform since it gets dropped\n",
    "y = df['y'].values\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='mean')  \n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_imputer', num_imputer, num_cols),\n",
    "        ('cat_imputer', cat_imputer, cat_cols)\n",
    "    ])\n",
    "\n",
    "df_imputed = pd.DataFrame(transformer.fit_transform(df), columns=num_cols+cat_cols)\n",
    "df_imputed.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0     0\n",
      "x1     0\n",
      "x2     0\n",
      "x3     0\n",
      "x4     0\n",
      "x5     0\n",
      "x6     0\n",
      "x7     0\n",
      "x8     0\n",
      "x9     0\n",
      "x10    0\n",
      "x11    0\n",
      "x12    0\n",
      "x13    0\n",
      "x14    0\n",
      "x15    0\n",
      "x16    0\n",
      "x17    0\n",
      "x18    0\n",
      "x19    0\n",
      "x20    0\n",
      "x21    0\n",
      "x22    0\n",
      "x23    0\n",
      "x25    0\n",
      "x26    0\n",
      "x27    0\n",
      "x28    0\n",
      "x31    0\n",
      "x32    0\n",
      "x33    0\n",
      "x34    0\n",
      "x35    0\n",
      "x36    0\n",
      "x37    0\n",
      "x38    0\n",
      "x39    0\n",
      "x40    0\n",
      "x41    0\n",
      "x42    0\n",
      "x43    0\n",
      "x44    0\n",
      "x45    0\n",
      "x46    0\n",
      "x47    0\n",
      "x48    0\n",
      "x49    0\n",
      "x24    0\n",
      "x29    0\n",
      "x30    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_na = df_imputed.isna().sum()\n",
    "print(count_na)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding the 'x24' that appears to be a continent, the x29 that is a month, and the x32 that is a weekday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>x24</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.00000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.00000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.00000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000</td>\n",
       "      <td>160000</td>\n",
       "      <td>160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>159975.000000</td>\n",
       "      <td>159976.000000</td>\n",
       "      <td>159963.000000</td>\n",
       "      <td>159964.000000</td>\n",
       "      <td>159975.000000</td>\n",
       "      <td>159964.000000</td>\n",
       "      <td>159975.00000</td>\n",
       "      <td>159974.000000</td>\n",
       "      <td>159980.00000</td>\n",
       "      <td>159971.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>159964.000000</td>\n",
       "      <td>159961.00000</td>\n",
       "      <td>159972.000000</td>\n",
       "      <td>159970.000000</td>\n",
       "      <td>159964.000000</td>\n",
       "      <td>159969.000000</td>\n",
       "      <td>159969.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>-1.150145</td>\n",
       "      <td>-0.024637</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>0.013582</td>\n",
       "      <td>-1.67067</td>\n",
       "      <td>-7.692795</td>\n",
       "      <td>-0.03054</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>-0.00625</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-12.755395</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.674224</td>\n",
       "      <td>asia</td>\n",
       "      <td>July</td>\n",
       "      <td>wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>138993</td>\n",
       "      <td>45599</td>\n",
       "      <td>101565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   x0             x1             x2             x3  \\\n",
       "count   160000.000000  160000.000000  160000.000000  160000.000000   \n",
       "unique  159975.000000  159976.000000  159963.000000  159964.000000   \n",
       "top         -0.001028       0.001358      -1.150145      -0.024637   \n",
       "freq        26.000000      25.000000      38.000000      37.000000   \n",
       "\n",
       "                   x4             x5            x6             x7  \\\n",
       "count   160000.000000  160000.000000  160000.00000  160000.000000   \n",
       "unique  159975.000000  159964.000000  159975.00000  159974.000000   \n",
       "top         -0.000549       0.013582      -1.67067      -7.692795   \n",
       "freq        26.000000      37.000000      26.00000      27.000000   \n",
       "\n",
       "                  x8             x9  ...            x43           x44  \\\n",
       "count   160000.00000  160000.000000  ...  160000.000000  160000.00000   \n",
       "unique  159980.00000  159971.000000  ...  159964.000000  159961.00000   \n",
       "top         -0.03054       0.005462  ...      -0.002091      -0.00625   \n",
       "freq        21.00000      30.000000  ...      37.000000      40.00000   \n",
       "\n",
       "                  x45            x46            x47            x48  \\\n",
       "count   160000.000000  160000.000000  160000.000000  160000.000000   \n",
       "unique  159972.000000  159970.000000  159964.000000  159969.000000   \n",
       "top          0.000885     -12.755395       0.028622      -0.000224   \n",
       "freq        29.000000      31.000000      37.000000      32.000000   \n",
       "\n",
       "                  x49     x24     x29        x30  \n",
       "count   160000.000000  160000  160000     160000  \n",
       "unique  159969.000000       3      12          5  \n",
       "top         -0.674224    asia    July  wednesday  \n",
       "freq        32.000000  138993   45599     101565  \n",
       "\n",
       "[4 rows x 50 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df_imputed, columns=['x24', 'x29', 'x30'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the data for a cross val predict like prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0               object\n",
       "x1               object\n",
       "x2               object\n",
       "x3               object\n",
       "x4               object\n",
       "                  ...  \n",
       "x30_friday        uint8\n",
       "x30_monday        uint8\n",
       "x30_thurday       uint8\n",
       "x30_tuesday       uint8\n",
       "x30_wednesday     uint8\n",
       "Length: 67, dtype: object"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the label values into y and the features into X\n",
    "\n",
    "X = df.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some data in a train and val split to perform the search of the best model\n",
    "#will circle back to using kfolds later\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2684616ae20>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation='relu'),\n",
    "            )\n",
    "        \n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(kt.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a keras_tuner RandomSearch to tune the training process and optimize the Neural Network\n",
    "# https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    hyperband_iterations=5,\n",
    "    seed=1234,\n",
    "    directory='hp_tuning',\n",
    "    project_name='CaseStudy7_Run_1',\n",
    "    overwrite=False,\n",
    "    seed=1234\n",
    ")\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 8\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1270 Complete [00h 01m 24s]\n",
      "val_accuracy: 0.9593750238418579\n",
      "\n",
      "Best val_accuracy So Far: 0.9731249809265137\n",
      "Total elapsed time: 12h 52m 08s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "#train the DNN with a hyper parameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=50,\n",
    "             validation_data=(X_val, y_val),\n",
    "             callbacks=[es_callback])\n",
    "\n",
    "#get the best hyperparameters and store them in a var\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing a  K Fold split\n",
    "The best hyperparameters from the Hyperband tuning algorithm will be used to predict all 160,000 predictions, with models training on 143,999 datapoints using a 10 k fold split to where a model will train on that fold's training data, and then predictions made on the test set.  All test sets predictions will be concatenated into a flat array of predictions and scored for accuracy against the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 448)               14784     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 448)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 449       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,353\n",
      "Trainable params: 40,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.build(input_shape=(None, 28,28))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [ 16000  16001  16002 ... 159997 159998 159999]\n",
      "test: [    0     1     2 ... 15997 15998 15999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [16000 16001 16002 ... 31997 31998 31999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [32000 32001 32002 ... 47997 47998 47999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [48000 48001 48002 ... 63997 63998 63999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [64000 64001 64002 ... 79997 79998 79999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [80000 80001 80002 ... 95997 95998 95999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [ 96000  96001  96002 ... 111997 111998 111999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [112000 112001 112002 ... 127997 127998 127999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [128000 128001 128002 ... 143997 143998 143999]\n",
      "train: [     0      1      2 ... 143997 143998 143999]\n",
      "test: [144000 144001 144002 ... 159997 159998 159999]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "indices = kf.split(X,y)\n",
    "for train_index, test_index in indices:\n",
    "    print(f\"train: {train_index}\")\n",
    "    print(f\"test: {test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.3319 - accuracy: 0.8536 - val_loss: 0.2388 - val_accuracy: 0.9046\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.2115 - accuracy: 0.9181 - val_loss: 0.1831 - val_accuracy: 0.9313\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1724 - accuracy: 0.9365 - val_loss: 0.1561 - val_accuracy: 0.9442\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1557 - accuracy: 0.9446 - val_loss: 0.1458 - val_accuracy: 0.9494\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1449 - accuracy: 0.9496 - val_loss: 0.1407 - val_accuracy: 0.9506\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1372 - accuracy: 0.9528 - val_loss: 0.1323 - val_accuracy: 0.9552\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1316 - accuracy: 0.9553 - val_loss: 0.1276 - val_accuracy: 0.9587\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1265 - accuracy: 0.9571 - val_loss: 0.1222 - val_accuracy: 0.9603\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1222 - accuracy: 0.9592 - val_loss: 0.1208 - val_accuracy: 0.9613\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1192 - accuracy: 0.9602 - val_loss: 0.1197 - val_accuracy: 0.9622\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1163 - accuracy: 0.9613 - val_loss: 0.1190 - val_accuracy: 0.9620\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1142 - accuracy: 0.9626 - val_loss: 0.1139 - val_accuracy: 0.9642\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1121 - accuracy: 0.9629 - val_loss: 0.1154 - val_accuracy: 0.9631\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1087 - accuracy: 0.9651 - val_loss: 0.1132 - val_accuracy: 0.9646\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1071 - accuracy: 0.9648 - val_loss: 0.1117 - val_accuracy: 0.9655\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1058 - accuracy: 0.9652 - val_loss: 0.1147 - val_accuracy: 0.9638\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1043 - accuracy: 0.9661 - val_loss: 0.1124 - val_accuracy: 0.9649\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1029 - accuracy: 0.9666 - val_loss: 0.1090 - val_accuracy: 0.9651\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1016 - accuracy: 0.9671 - val_loss: 0.1101 - val_accuracy: 0.9650\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0997 - accuracy: 0.9680 - val_loss: 0.1110 - val_accuracy: 0.9657\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0985 - accuracy: 0.9683 - val_loss: 0.1054 - val_accuracy: 0.9685\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0981 - accuracy: 0.9686 - val_loss: 0.1059 - val_accuracy: 0.9671\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0975 - accuracy: 0.9690 - val_loss: 0.1075 - val_accuracy: 0.9668\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0956 - accuracy: 0.9697 - val_loss: 0.1090 - val_accuracy: 0.9674\n",
      "Epoch 25/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0948 - accuracy: 0.9699 - val_loss: 0.1051 - val_accuracy: 0.9684\n",
      "Epoch 26/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0936 - accuracy: 0.9705 - val_loss: 0.1035 - val_accuracy: 0.9701\n",
      "Epoch 27/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0930 - accuracy: 0.9700 - val_loss: 0.1071 - val_accuracy: 0.9679\n",
      "Epoch 28/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0917 - accuracy: 0.9707 - val_loss: 0.1067 - val_accuracy: 0.9688\n",
      "Epoch 29/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0915 - accuracy: 0.9712 - val_loss: 0.1080 - val_accuracy: 0.9678\n",
      "Epoch 30/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0906 - accuracy: 0.9715 - val_loss: 0.1065 - val_accuracy: 0.9688\n",
      "Epoch 31/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0900 - accuracy: 0.9722 - val_loss: 0.1036 - val_accuracy: 0.9687\n",
      "500/500 [==============================] - 0s 768us/step\n",
      "Iteration 1\n",
      "Precision:  0.9614547715262667\n",
      "Recall:  0.9566965666563563\n",
      "F1 Score:  0.9590697674418605\n",
      "Confusion Matrix: \n",
      " [[9286  248]\n",
      " [ 280 6186]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.3340 - accuracy: 0.8524 - val_loss: 0.2370 - val_accuracy: 0.9055\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.2031 - accuracy: 0.9207 - val_loss: 0.1783 - val_accuracy: 0.9322\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1683 - accuracy: 0.9376 - val_loss: 0.1555 - val_accuracy: 0.9438\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1516 - accuracy: 0.9457 - val_loss: 0.1441 - val_accuracy: 0.9492\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1402 - accuracy: 0.9508 - val_loss: 0.1365 - val_accuracy: 0.9536\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1325 - accuracy: 0.9546 - val_loss: 0.1320 - val_accuracy: 0.9560\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1263 - accuracy: 0.9570 - val_loss: 0.1344 - val_accuracy: 0.9574\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1219 - accuracy: 0.9588 - val_loss: 0.1220 - val_accuracy: 0.9610\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1181 - accuracy: 0.9603 - val_loss: 0.1198 - val_accuracy: 0.9605\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1156 - accuracy: 0.9617 - val_loss: 0.1177 - val_accuracy: 0.9631\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1114 - accuracy: 0.9635 - val_loss: 0.1174 - val_accuracy: 0.9641\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1096 - accuracy: 0.9641 - val_loss: 0.1122 - val_accuracy: 0.9645\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1079 - accuracy: 0.9645 - val_loss: 0.1134 - val_accuracy: 0.9639\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1053 - accuracy: 0.9659 - val_loss: 0.1120 - val_accuracy: 0.9652\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1043 - accuracy: 0.9663 - val_loss: 0.1120 - val_accuracy: 0.9649\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1032 - accuracy: 0.9669 - val_loss: 0.1111 - val_accuracy: 0.9655\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1013 - accuracy: 0.9679 - val_loss: 0.1064 - val_accuracy: 0.9673\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0992 - accuracy: 0.9685 - val_loss: 0.1080 - val_accuracy: 0.9673\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0979 - accuracy: 0.9690 - val_loss: 0.1062 - val_accuracy: 0.9675\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0973 - accuracy: 0.9689 - val_loss: 0.1089 - val_accuracy: 0.9668\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0962 - accuracy: 0.9700 - val_loss: 0.1060 - val_accuracy: 0.9684\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0959 - accuracy: 0.9696 - val_loss: 0.1067 - val_accuracy: 0.9681\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0951 - accuracy: 0.9700 - val_loss: 0.1048 - val_accuracy: 0.9687\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0938 - accuracy: 0.9697 - val_loss: 0.1047 - val_accuracy: 0.9690\n",
      "Epoch 25/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0934 - accuracy: 0.9701 - val_loss: 0.1042 - val_accuracy: 0.9682\n",
      "Epoch 26/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0919 - accuracy: 0.9707 - val_loss: 0.1050 - val_accuracy: 0.9689\n",
      "Epoch 27/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0915 - accuracy: 0.9709 - val_loss: 0.1100 - val_accuracy: 0.9674\n",
      "Epoch 28/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0915 - accuracy: 0.9709 - val_loss: 0.1047 - val_accuracy: 0.9689\n",
      "Epoch 29/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0894 - accuracy: 0.9718 - val_loss: 0.1054 - val_accuracy: 0.9686\n",
      "Epoch 30/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0890 - accuracy: 0.9720 - val_loss: 0.1050 - val_accuracy: 0.9701\n",
      "500/500 [==============================] - 0s 569us/step\n",
      "Iteration 2\n",
      "Precision:  0.9673119644557283\n",
      "Recall:  0.9525\n",
      "F1 Score:  0.9598488427019367\n",
      "Confusion Matrix: \n",
      " [[9394  206]\n",
      " [ 304 6096]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.3362 - accuracy: 0.8526 - val_loss: 0.2374 - val_accuracy: 0.9050\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.2098 - accuracy: 0.9197 - val_loss: 0.1810 - val_accuracy: 0.9324\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1719 - accuracy: 0.9376 - val_loss: 0.1586 - val_accuracy: 0.9440\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 1ms/step - loss: 0.1525 - accuracy: 0.9463 - val_loss: 0.1461 - val_accuracy: 0.9497\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1427 - accuracy: 0.9504 - val_loss: 0.1363 - val_accuracy: 0.9539\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1348 - accuracy: 0.9544 - val_loss: 0.1342 - val_accuracy: 0.9561\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1284 - accuracy: 0.9572 - val_loss: 0.1304 - val_accuracy: 0.9572\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1233 - accuracy: 0.9592 - val_loss: 0.1232 - val_accuracy: 0.9605\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1194 - accuracy: 0.9609 - val_loss: 0.1189 - val_accuracy: 0.9624\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1162 - accuracy: 0.9614 - val_loss: 0.1216 - val_accuracy: 0.9620\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1129 - accuracy: 0.9640 - val_loss: 0.1230 - val_accuracy: 0.9621\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1109 - accuracy: 0.9645 - val_loss: 0.1195 - val_accuracy: 0.9623\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1082 - accuracy: 0.9649 - val_loss: 0.1152 - val_accuracy: 0.9652\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1073 - accuracy: 0.9663 - val_loss: 0.1131 - val_accuracy: 0.9650\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1050 - accuracy: 0.9663 - val_loss: 0.1174 - val_accuracy: 0.9636\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1033 - accuracy: 0.9672 - val_loss: 0.1118 - val_accuracy: 0.9669\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1029 - accuracy: 0.9672 - val_loss: 0.1123 - val_accuracy: 0.9670\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1013 - accuracy: 0.9682 - val_loss: 0.1110 - val_accuracy: 0.9672\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1002 - accuracy: 0.9684 - val_loss: 0.1134 - val_accuracy: 0.9669\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0981 - accuracy: 0.9691 - val_loss: 0.1102 - val_accuracy: 0.9666\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0972 - accuracy: 0.9698 - val_loss: 0.1105 - val_accuracy: 0.9673\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0966 - accuracy: 0.9699 - val_loss: 0.1112 - val_accuracy: 0.9658\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0956 - accuracy: 0.9700 - val_loss: 0.1113 - val_accuracy: 0.9669\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0946 - accuracy: 0.9712 - val_loss: 0.1103 - val_accuracy: 0.9673\n",
      "Epoch 25/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0942 - accuracy: 0.9704 - val_loss: 0.1085 - val_accuracy: 0.9685\n",
      "Epoch 26/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0931 - accuracy: 0.9714 - val_loss: 0.1071 - val_accuracy: 0.9685\n",
      "Epoch 27/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0922 - accuracy: 0.9715 - val_loss: 0.1118 - val_accuracy: 0.9677\n",
      "Epoch 28/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0911 - accuracy: 0.9714 - val_loss: 0.1076 - val_accuracy: 0.9692\n",
      "Epoch 29/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0909 - accuracy: 0.9714 - val_loss: 0.1076 - val_accuracy: 0.9685\n",
      "Epoch 30/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0904 - accuracy: 0.9720 - val_loss: 0.1063 - val_accuracy: 0.9691\n",
      "Epoch 31/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0894 - accuracy: 0.9724 - val_loss: 0.1075 - val_accuracy: 0.9688\n",
      "Epoch 32/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0888 - accuracy: 0.9723 - val_loss: 0.1104 - val_accuracy: 0.9685\n",
      "Epoch 33/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0884 - accuracy: 0.9726 - val_loss: 0.1113 - val_accuracy: 0.9682\n",
      "Epoch 34/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0882 - accuracy: 0.9728 - val_loss: 0.1091 - val_accuracy: 0.9685\n",
      "Epoch 35/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0868 - accuracy: 0.9732 - val_loss: 0.1078 - val_accuracy: 0.9686\n",
      "500/500 [==============================] - 0s 700us/step\n",
      "Iteration 3\n",
      "Precision:  0.9685162094763092\n",
      "Recall:  0.9549715690794529\n",
      "F1 Score:  0.9616962005726224\n",
      "Confusion Matrix: \n",
      " [[9291  202]\n",
      " [ 293 6214]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.3368 - accuracy: 0.8512 - val_loss: 0.2475 - val_accuracy: 0.9010\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.2181 - accuracy: 0.9143 - val_loss: 0.1883 - val_accuracy: 0.9316\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1781 - accuracy: 0.9345 - val_loss: 0.1629 - val_accuracy: 0.9421\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1598 - accuracy: 0.9427 - val_loss: 0.1467 - val_accuracy: 0.9489\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1499 - accuracy: 0.9471 - val_loss: 0.1433 - val_accuracy: 0.9515\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1413 - accuracy: 0.9508 - val_loss: 0.1366 - val_accuracy: 0.9529\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 1ms/step - loss: 0.1365 - accuracy: 0.9530 - val_loss: 0.1318 - val_accuracy: 0.9563\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1311 - accuracy: 0.9550 - val_loss: 0.1285 - val_accuracy: 0.9589\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1272 - accuracy: 0.9567 - val_loss: 0.1298 - val_accuracy: 0.9575\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1245 - accuracy: 0.9582 - val_loss: 0.1223 - val_accuracy: 0.9608\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1219 - accuracy: 0.9595 - val_loss: 0.1241 - val_accuracy: 0.9586\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1174 - accuracy: 0.9611 - val_loss: 0.1209 - val_accuracy: 0.9616\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1164 - accuracy: 0.9611 - val_loss: 0.1188 - val_accuracy: 0.9616\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1149 - accuracy: 0.9623 - val_loss: 0.1199 - val_accuracy: 0.9617\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1108 - accuracy: 0.9632 - val_loss: 0.1190 - val_accuracy: 0.9640\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1087 - accuracy: 0.9647 - val_loss: 0.1169 - val_accuracy: 0.9630\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1074 - accuracy: 0.9650 - val_loss: 0.1205 - val_accuracy: 0.9624\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1063 - accuracy: 0.9654 - val_loss: 0.1174 - val_accuracy: 0.9635\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1047 - accuracy: 0.9664 - val_loss: 0.1147 - val_accuracy: 0.9643\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1032 - accuracy: 0.9667 - val_loss: 0.1148 - val_accuracy: 0.9657\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1003 - accuracy: 0.9681 - val_loss: 0.1157 - val_accuracy: 0.9636\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1005 - accuracy: 0.9677 - val_loss: 0.1144 - val_accuracy: 0.9652\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0997 - accuracy: 0.9688 - val_loss: 0.1103 - val_accuracy: 0.9668\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0989 - accuracy: 0.9688 - val_loss: 0.1151 - val_accuracy: 0.9664\n",
      "Epoch 25/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0973 - accuracy: 0.9692 - val_loss: 0.1093 - val_accuracy: 0.9676\n",
      "Epoch 26/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0971 - accuracy: 0.9696 - val_loss: 0.1110 - val_accuracy: 0.9665\n",
      "Epoch 27/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0948 - accuracy: 0.9702 - val_loss: 0.1107 - val_accuracy: 0.9666\n",
      "Epoch 28/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0942 - accuracy: 0.9700 - val_loss: 0.1109 - val_accuracy: 0.9671\n",
      "Epoch 29/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0942 - accuracy: 0.9706 - val_loss: 0.1111 - val_accuracy: 0.9665\n",
      "Epoch 30/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0933 - accuracy: 0.9706 - val_loss: 0.1098 - val_accuracy: 0.9675\n",
      "500/500 [==============================] - 0s 594us/step\n",
      "Iteration 4\n",
      "Precision:  0.957032457496136\n",
      "Recall:  0.961789375582479\n",
      "F1 Score:  0.9594050201425474\n",
      "Confusion Matrix: \n",
      " [[9284  278]\n",
      " [ 246 6192]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.3274 - accuracy: 0.8554 - val_loss: 0.2409 - val_accuracy: 0.9021\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.2111 - accuracy: 0.9174 - val_loss: 0.1817 - val_accuracy: 0.9311\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1733 - accuracy: 0.9356 - val_loss: 0.1600 - val_accuracy: 0.9420\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1538 - accuracy: 0.9450 - val_loss: 0.1474 - val_accuracy: 0.9475\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1414 - accuracy: 0.9505 - val_loss: 0.1410 - val_accuracy: 0.9508\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1336 - accuracy: 0.9533 - val_loss: 0.1315 - val_accuracy: 0.9557\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1295 - accuracy: 0.9558 - val_loss: 0.1270 - val_accuracy: 0.9556\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1244 - accuracy: 0.9583 - val_loss: 0.1236 - val_accuracy: 0.9587\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1212 - accuracy: 0.9589 - val_loss: 0.1230 - val_accuracy: 0.9592\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1179 - accuracy: 0.9610 - val_loss: 0.1208 - val_accuracy: 0.9613\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1154 - accuracy: 0.9620 - val_loss: 0.1169 - val_accuracy: 0.9628\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1131 - accuracy: 0.9624 - val_loss: 0.1159 - val_accuracy: 0.9630\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1111 - accuracy: 0.9635 - val_loss: 0.1133 - val_accuracy: 0.9650\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1091 - accuracy: 0.9642 - val_loss: 0.1120 - val_accuracy: 0.9654\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1084 - accuracy: 0.9645 - val_loss: 0.1152 - val_accuracy: 0.9639\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1061 - accuracy: 0.9655 - val_loss: 0.1103 - val_accuracy: 0.9647\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1054 - accuracy: 0.9659 - val_loss: 0.1112 - val_accuracy: 0.9669\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1035 - accuracy: 0.9667 - val_loss: 0.1133 - val_accuracy: 0.9640\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1030 - accuracy: 0.9667 - val_loss: 0.1136 - val_accuracy: 0.9654\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1009 - accuracy: 0.9676 - val_loss: 0.1114 - val_accuracy: 0.9663\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1001 - accuracy: 0.9680 - val_loss: 0.1082 - val_accuracy: 0.9672\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0999 - accuracy: 0.9680 - val_loss: 0.1097 - val_accuracy: 0.9671\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0979 - accuracy: 0.9690 - val_loss: 0.1127 - val_accuracy: 0.9669\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0979 - accuracy: 0.9685 - val_loss: 0.1097 - val_accuracy: 0.9680\n",
      "Epoch 25/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0965 - accuracy: 0.9692 - val_loss: 0.1083 - val_accuracy: 0.9678\n",
      "Epoch 26/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0957 - accuracy: 0.9692 - val_loss: 0.1056 - val_accuracy: 0.9694\n",
      "Epoch 27/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0951 - accuracy: 0.9696 - val_loss: 0.1079 - val_accuracy: 0.9679\n",
      "Epoch 28/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0931 - accuracy: 0.9703 - val_loss: 0.1115 - val_accuracy: 0.9669\n",
      "Epoch 29/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0938 - accuracy: 0.9700 - val_loss: 0.1081 - val_accuracy: 0.9676\n",
      "Epoch 30/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0932 - accuracy: 0.9705 - val_loss: 0.1093 - val_accuracy: 0.9680\n",
      "Epoch 31/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0919 - accuracy: 0.9707 - val_loss: 0.1081 - val_accuracy: 0.9686\n",
      "500/500 [==============================] - 0s 660us/step\n",
      "Iteration 5\n",
      "Precision:  0.9695543000627747\n",
      "Recall:  0.9547210632050688\n",
      "F1 Score:  0.9620805107840846\n",
      "Confusion Matrix: \n",
      " [[9335  194]\n",
      " [ 293 6178]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.3287 - accuracy: 0.8549 - val_loss: 0.2437 - val_accuracy: 0.9026\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.2093 - accuracy: 0.9190 - val_loss: 0.1874 - val_accuracy: 0.9309\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1729 - accuracy: 0.9368 - val_loss: 0.1611 - val_accuracy: 0.9428\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1547 - accuracy: 0.9447 - val_loss: 0.1511 - val_accuracy: 0.9466\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1448 - accuracy: 0.9492 - val_loss: 0.1482 - val_accuracy: 0.9470\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1372 - accuracy: 0.9527 - val_loss: 0.1368 - val_accuracy: 0.9529\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1323 - accuracy: 0.9551 - val_loss: 0.1351 - val_accuracy: 0.9543\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1277 - accuracy: 0.9572 - val_loss: 0.1298 - val_accuracy: 0.9576\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1250 - accuracy: 0.9571 - val_loss: 0.1260 - val_accuracy: 0.9578\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1213 - accuracy: 0.9593 - val_loss: 0.1253 - val_accuracy: 0.9592\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1189 - accuracy: 0.9602 - val_loss: 0.1259 - val_accuracy: 0.9584\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1161 - accuracy: 0.9615 - val_loss: 0.1252 - val_accuracy: 0.9591\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1147 - accuracy: 0.9611 - val_loss: 0.1233 - val_accuracy: 0.9606\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1127 - accuracy: 0.9625 - val_loss: 0.1181 - val_accuracy: 0.9630\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1102 - accuracy: 0.9635 - val_loss: 0.1199 - val_accuracy: 0.9625\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1084 - accuracy: 0.9639 - val_loss: 0.1211 - val_accuracy: 0.9614\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1080 - accuracy: 0.9643 - val_loss: 0.1186 - val_accuracy: 0.9615\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1062 - accuracy: 0.9650 - val_loss: 0.1195 - val_accuracy: 0.9625\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1048 - accuracy: 0.9659 - val_loss: 0.1159 - val_accuracy: 0.9631\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1031 - accuracy: 0.9664 - val_loss: 0.1154 - val_accuracy: 0.9628\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1017 - accuracy: 0.9670 - val_loss: 0.1170 - val_accuracy: 0.9636\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1015 - accuracy: 0.9671 - val_loss: 0.1149 - val_accuracy: 0.9650\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1006 - accuracy: 0.9674 - val_loss: 0.1171 - val_accuracy: 0.9650\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0998 - accuracy: 0.9675 - val_loss: 0.1160 - val_accuracy: 0.9639\n",
      "Epoch 25/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0993 - accuracy: 0.9676 - val_loss: 0.1165 - val_accuracy: 0.9645\n",
      "Epoch 26/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0982 - accuracy: 0.9682 - val_loss: 0.1151 - val_accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0973 - accuracy: 0.9682 - val_loss: 0.1165 - val_accuracy: 0.9638\n",
      "500/500 [==============================] - 0s 694us/step\n",
      "Iteration 6\n",
      "Precision:  0.9619591060389919\n",
      "Recall:  0.952149356761845\n",
      "F1 Score:  0.9570290940629189\n",
      "Confusion Matrix: \n",
      " [[9386  240]\n",
      " [ 305 6069]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 6s 1ms/step - loss: 0.3304 - accuracy: 0.8538 - val_loss: 0.2290 - val_accuracy: 0.9102\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.2044 - accuracy: 0.9209 - val_loss: 0.1877 - val_accuracy: 0.9299\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1726 - accuracy: 0.9361 - val_loss: 0.1622 - val_accuracy: 0.9423\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1571 - accuracy: 0.9432 - val_loss: 0.1493 - val_accuracy: 0.9473\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1474 - accuracy: 0.9475 - val_loss: 0.1403 - val_accuracy: 0.9513\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1412 - accuracy: 0.9504 - val_loss: 0.1377 - val_accuracy: 0.9540\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1363 - accuracy: 0.9525 - val_loss: 0.1356 - val_accuracy: 0.9557\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 5s 1ms/step - loss: 0.1330 - accuracy: 0.9540 - val_loss: 0.1315 - val_accuracy: 0.9573\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1285 - accuracy: 0.9560 - val_loss: 0.1292 - val_accuracy: 0.9579\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1244 - accuracy: 0.9571 - val_loss: 0.1280 - val_accuracy: 0.9576\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1233 - accuracy: 0.9583 - val_loss: 0.1268 - val_accuracy: 0.9588\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1202 - accuracy: 0.9592 - val_loss: 0.1266 - val_accuracy: 0.9593\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1179 - accuracy: 0.9607 - val_loss: 0.1190 - val_accuracy: 0.9612\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1161 - accuracy: 0.9610 - val_loss: 0.1215 - val_accuracy: 0.9618\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1129 - accuracy: 0.9626 - val_loss: 0.1172 - val_accuracy: 0.9637\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1127 - accuracy: 0.9623 - val_loss: 0.1238 - val_accuracy: 0.9601\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1109 - accuracy: 0.9634 - val_loss: 0.1165 - val_accuracy: 0.9635\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1094 - accuracy: 0.9642 - val_loss: 0.1175 - val_accuracy: 0.9628\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1084 - accuracy: 0.9636 - val_loss: 0.1157 - val_accuracy: 0.9637\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1063 - accuracy: 0.9647 - val_loss: 0.1160 - val_accuracy: 0.9647\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1062 - accuracy: 0.9653 - val_loss: 0.1164 - val_accuracy: 0.9638\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1043 - accuracy: 0.9657 - val_loss: 0.1185 - val_accuracy: 0.9641\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1037 - accuracy: 0.9664 - val_loss: 0.1119 - val_accuracy: 0.9656\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1025 - accuracy: 0.9664 - val_loss: 0.1133 - val_accuracy: 0.9649\n",
      "Epoch 25/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1007 - accuracy: 0.9677 - val_loss: 0.1145 - val_accuracy: 0.9660\n",
      "Epoch 26/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1000 - accuracy: 0.9681 - val_loss: 0.1168 - val_accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0987 - accuracy: 0.9678 - val_loss: 0.1142 - val_accuracy: 0.9661\n",
      "Epoch 28/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0982 - accuracy: 0.9682 - val_loss: 0.1125 - val_accuracy: 0.9657\n",
      "500/500 [==============================] - 0s 849us/step\n",
      "Iteration 7\n",
      "Precision:  0.9677683246073299\n",
      "Recall:  0.938590923516344\n",
      "F1 Score:  0.952956339616562\n",
      "Confusion Matrix: \n",
      " [[9501  197]\n",
      " [ 387 5915]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.3236 - accuracy: 0.8585 - val_loss: 0.2284 - val_accuracy: 0.9103\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.2031 - accuracy: 0.9216 - val_loss: 0.1792 - val_accuracy: 0.9350\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1666 - accuracy: 0.9390 - val_loss: 0.1553 - val_accuracy: 0.9449\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1497 - accuracy: 0.9465 - val_loss: 0.1459 - val_accuracy: 0.9503\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1383 - accuracy: 0.9522 - val_loss: 0.1321 - val_accuracy: 0.9567\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1308 - accuracy: 0.9552 - val_loss: 0.1322 - val_accuracy: 0.9553\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1256 - accuracy: 0.9580 - val_loss: 0.1254 - val_accuracy: 0.9614\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1218 - accuracy: 0.9591 - val_loss: 0.1223 - val_accuracy: 0.9614\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1171 - accuracy: 0.9613 - val_loss: 0.1207 - val_accuracy: 0.9617\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1157 - accuracy: 0.9621 - val_loss: 0.1151 - val_accuracy: 0.9632\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1130 - accuracy: 0.9637 - val_loss: 0.1149 - val_accuracy: 0.9643\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1105 - accuracy: 0.9640 - val_loss: 0.1109 - val_accuracy: 0.9656\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1091 - accuracy: 0.9645 - val_loss: 0.1106 - val_accuracy: 0.9664\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1072 - accuracy: 0.9653 - val_loss: 0.1088 - val_accuracy: 0.9664\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1054 - accuracy: 0.9663 - val_loss: 0.1132 - val_accuracy: 0.9652\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1027 - accuracy: 0.9672 - val_loss: 0.1123 - val_accuracy: 0.9664\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1017 - accuracy: 0.9679 - val_loss: 0.1098 - val_accuracy: 0.9670\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1011 - accuracy: 0.9675 - val_loss: 0.1056 - val_accuracy: 0.9679\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0999 - accuracy: 0.9684 - val_loss: 0.1020 - val_accuracy: 0.9696\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0987 - accuracy: 0.9686 - val_loss: 0.1065 - val_accuracy: 0.9687\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0970 - accuracy: 0.9694 - val_loss: 0.1081 - val_accuracy: 0.9685\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0966 - accuracy: 0.9699 - val_loss: 0.1079 - val_accuracy: 0.9676\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0943 - accuracy: 0.9696 - val_loss: 0.1050 - val_accuracy: 0.9692\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0949 - accuracy: 0.9703 - val_loss: 0.1088 - val_accuracy: 0.9681\n",
      "500/500 [==============================] - 0s 572us/step\n",
      "Iteration 8\n",
      "Precision:  0.9582483126667714\n",
      "Recall:  0.9522695367337389\n",
      "F1 Score:  0.955249569707401\n",
      "Confusion Matrix: \n",
      " [[9323  266]\n",
      " [ 306 6105]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.3207 - accuracy: 0.8597 - val_loss: 0.2279 - val_accuracy: 0.9099\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1991 - accuracy: 0.9230 - val_loss: 0.1776 - val_accuracy: 0.9326\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 6s 1ms/step - loss: 0.1671 - accuracy: 0.9389 - val_loss: 0.1535 - val_accuracy: 0.9457\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 1ms/step - loss: 0.1503 - accuracy: 0.9470 - val_loss: 0.1417 - val_accuracy: 0.9518\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.1341 - val_accuracy: 0.9560\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1333 - accuracy: 0.9543 - val_loss: 0.1300 - val_accuracy: 0.9562\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1282 - accuracy: 0.9564 - val_loss: 0.1281 - val_accuracy: 0.9582\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1237 - accuracy: 0.9587 - val_loss: 0.1230 - val_accuracy: 0.9598\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1191 - accuracy: 0.9605 - val_loss: 0.1243 - val_accuracy: 0.9593\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1161 - accuracy: 0.9617 - val_loss: 0.1193 - val_accuracy: 0.9625\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1130 - accuracy: 0.9632 - val_loss: 0.1197 - val_accuracy: 0.9615\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1114 - accuracy: 0.9630 - val_loss: 0.1172 - val_accuracy: 0.9629\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1095 - accuracy: 0.9639 - val_loss: 0.1180 - val_accuracy: 0.9634\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1079 - accuracy: 0.9650 - val_loss: 0.1183 - val_accuracy: 0.9628\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1064 - accuracy: 0.9656 - val_loss: 0.1126 - val_accuracy: 0.9639\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1043 - accuracy: 0.9667 - val_loss: 0.1142 - val_accuracy: 0.9660\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1032 - accuracy: 0.9669 - val_loss: 0.1154 - val_accuracy: 0.9644\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1020 - accuracy: 0.9666 - val_loss: 0.1132 - val_accuracy: 0.9656\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1008 - accuracy: 0.9672 - val_loss: 0.1116 - val_accuracy: 0.9680\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1009 - accuracy: 0.9677 - val_loss: 0.1126 - val_accuracy: 0.9674\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0980 - accuracy: 0.9687 - val_loss: 0.1099 - val_accuracy: 0.9672\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0984 - accuracy: 0.9693 - val_loss: 0.1125 - val_accuracy: 0.9667\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0969 - accuracy: 0.9697 - val_loss: 0.1120 - val_accuracy: 0.9656\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0969 - accuracy: 0.9690 - val_loss: 0.1104 - val_accuracy: 0.9674\n",
      "Epoch 25/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0953 - accuracy: 0.9696 - val_loss: 0.1132 - val_accuracy: 0.9666\n",
      "Epoch 26/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0947 - accuracy: 0.9696 - val_loss: 0.1099 - val_accuracy: 0.9671\n",
      "500/500 [==============================] - 0s 631us/step\n",
      "Iteration 9\n",
      "Precision:  0.9623681310029917\n",
      "Recall:  0.9509880192936051\n",
      "F1 Score:  0.9566442322742214\n",
      "Confusion Matrix: \n",
      " [[9334  239]\n",
      " [ 315 6112]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.3261 - accuracy: 0.8571 - val_loss: 0.2298 - val_accuracy: 0.9088\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.2019 - accuracy: 0.9223 - val_loss: 0.1785 - val_accuracy: 0.9328\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1680 - accuracy: 0.9385 - val_loss: 0.1536 - val_accuracy: 0.9444\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1518 - accuracy: 0.9461 - val_loss: 0.1458 - val_accuracy: 0.9496\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1416 - accuracy: 0.9507 - val_loss: 0.1372 - val_accuracy: 0.9524\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1336 - accuracy: 0.9536 - val_loss: 0.1298 - val_accuracy: 0.9571\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1282 - accuracy: 0.9566 - val_loss: 0.1246 - val_accuracy: 0.9588\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1242 - accuracy: 0.9582 - val_loss: 0.1207 - val_accuracy: 0.9607\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1195 - accuracy: 0.9606 - val_loss: 0.1232 - val_accuracy: 0.9606\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1158 - accuracy: 0.9618 - val_loss: 0.1178 - val_accuracy: 0.9630\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1124 - accuracy: 0.9634 - val_loss: 0.1131 - val_accuracy: 0.9645\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1094 - accuracy: 0.9648 - val_loss: 0.1126 - val_accuracy: 0.9649\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1087 - accuracy: 0.9658 - val_loss: 0.1089 - val_accuracy: 0.9663\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1056 - accuracy: 0.9657 - val_loss: 0.1128 - val_accuracy: 0.9642\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1035 - accuracy: 0.9669 - val_loss: 0.1103 - val_accuracy: 0.9656\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1013 - accuracy: 0.9672 - val_loss: 0.1074 - val_accuracy: 0.9674\n",
      "Epoch 17/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.1001 - accuracy: 0.9683 - val_loss: 0.1106 - val_accuracy: 0.9648\n",
      "Epoch 18/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0980 - accuracy: 0.9687 - val_loss: 0.1071 - val_accuracy: 0.9669\n",
      "Epoch 19/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0973 - accuracy: 0.9694 - val_loss: 0.1090 - val_accuracy: 0.9668\n",
      "Epoch 20/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0970 - accuracy: 0.9694 - val_loss: 0.1067 - val_accuracy: 0.9672\n",
      "Epoch 21/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0952 - accuracy: 0.9703 - val_loss: 0.1019 - val_accuracy: 0.9691\n",
      "Epoch 22/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0943 - accuracy: 0.9702 - val_loss: 0.1055 - val_accuracy: 0.9674\n",
      "Epoch 23/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0922 - accuracy: 0.9713 - val_loss: 0.0994 - val_accuracy: 0.9718\n",
      "Epoch 24/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0920 - accuracy: 0.9711 - val_loss: 0.0985 - val_accuracy: 0.9706\n",
      "Epoch 25/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0906 - accuracy: 0.9716 - val_loss: 0.0995 - val_accuracy: 0.9697\n",
      "Epoch 26/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0897 - accuracy: 0.9722 - val_loss: 0.0981 - val_accuracy: 0.9703\n",
      "Epoch 27/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0893 - accuracy: 0.9718 - val_loss: 0.0979 - val_accuracy: 0.9705\n",
      "Epoch 28/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0878 - accuracy: 0.9726 - val_loss: 0.1010 - val_accuracy: 0.9711\n",
      "Epoch 29/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0871 - accuracy: 0.9732 - val_loss: 0.0949 - val_accuracy: 0.9719\n",
      "Epoch 30/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0861 - accuracy: 0.9733 - val_loss: 0.0996 - val_accuracy: 0.9710\n",
      "Epoch 31/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0856 - accuracy: 0.9736 - val_loss: 0.0993 - val_accuracy: 0.9708\n",
      "Epoch 32/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0862 - accuracy: 0.9734 - val_loss: 0.0980 - val_accuracy: 0.9716\n",
      "Epoch 33/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0845 - accuracy: 0.9738 - val_loss: 0.0983 - val_accuracy: 0.9718\n",
      "Epoch 34/100\n",
      "3825/3825 [==============================] - 6s 2ms/step - loss: 0.0842 - accuracy: 0.9739 - val_loss: 0.0974 - val_accuracy: 0.9718\n",
      "500/500 [==============================] - 0s 601us/step\n",
      "Iteration 10\n",
      "Precision:  0.9658039215686275\n",
      "Recall:  0.9618809561006093\n",
      "F1 Score:  0.9638384470882905\n",
      "Confusion Matrix: \n",
      " [[9381  218]\n",
      " [ 244 6157]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = []\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    best_model = tuner.hypermodel.build(best_hps) #have to create a new instance of the model to ensure  it doesn't reload anything that it was previously trained on\n",
    "    X_train_val, X_test = X[train_index], X[test_index]\n",
    "    y_train_val, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.15, random_state=1234)\n",
    "    best_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[es_callback])\n",
    "    y_prob = best_model.predict(X_test)\n",
    "    y_pred = (y_prob > 0.5).astype(\"int32\")\n",
    "    predictions.append(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Iteration {i}\")\n",
    "    print(f\"Accuracy {accuracy}\")\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"Confusion Matrix: \\n\", confusion)\n",
    "    i = i+1\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Scoring of the Neural Network Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.96711875\n",
      "Precision:  0.9639753117521098\n",
      "Recall:  0.9536894247394738\n",
      "F1 Score:  0.9588047827482793\n",
      "Confusion Matrix: \n",
      " [[93515  2288]\n",
      " [ 2973 61224]]\n",
      "Final Cost: $ 674,750.00\n"
     ]
    }
   ],
   "source": [
    "full_predictions = np.concatenate(predictions)\n",
    "accuracy = accuracy_score(y, full_predictions)\n",
    "precision = precision_score(y, full_predictions)\n",
    "recall = recall_score(y, full_predictions)\n",
    "f1 = f1_score(y, full_predictions)\n",
    "confusion = confusion_matrix(y, full_predictions)\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"Confusion Matrix: \\n\", confusion)\n",
    "cost = (confusion[0,1] * 100) + (confusion[1,0]*150) \n",
    "print(f\"Final Cost: $ {'{:,.2f}'.format(cost)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 2, 'units_0': 32, 'dropout': True, 'lr': 0.0009259685801345267, 'units_1': 448, 'units_2': 224, 'units_3': 288, 'units_4': 288, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0737'}\n"
     ]
    }
   ],
   "source": [
    "print(best_hps.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
