{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_project.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0     float64\n",
       "x1     float64\n",
       "x2     float64\n",
       "x3     float64\n",
       "x4     float64\n",
       "x5     float64\n",
       "x6     float64\n",
       "x7     float64\n",
       "x8     float64\n",
       "x9     float64\n",
       "x10    float64\n",
       "x11    float64\n",
       "x12    float64\n",
       "x13    float64\n",
       "x14    float64\n",
       "x15    float64\n",
       "x16    float64\n",
       "x17    float64\n",
       "x18    float64\n",
       "x19    float64\n",
       "x20    float64\n",
       "x21    float64\n",
       "x22    float64\n",
       "x23    float64\n",
       "x24     object\n",
       "x25    float64\n",
       "x26    float64\n",
       "x27    float64\n",
       "x28    float64\n",
       "x29     object\n",
       "x30     object\n",
       "x31    float64\n",
       "x32     object\n",
       "x33    float64\n",
       "x34    float64\n",
       "x35    float64\n",
       "x36    float64\n",
       "x37     object\n",
       "x38    float64\n",
       "x39    float64\n",
       "x40    float64\n",
       "x41    float64\n",
       "x42    float64\n",
       "x43    float64\n",
       "x44    float64\n",
       "x45    float64\n",
       "x46    float64\n",
       "x47    float64\n",
       "x48    float64\n",
       "x49    float64\n",
       "y        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0     26\n",
      "x1     25\n",
      "x2     38\n",
      "x3     37\n",
      "x4     26\n",
      "x5     37\n",
      "x6     26\n",
      "x7     27\n",
      "x8     21\n",
      "x9     30\n",
      "x10    43\n",
      "x11    30\n",
      "x12    36\n",
      "x13    31\n",
      "x14    34\n",
      "x15    35\n",
      "x16    26\n",
      "x17    27\n",
      "x18    40\n",
      "x19    35\n",
      "x20    38\n",
      "x21    29\n",
      "x22    27\n",
      "x23    47\n",
      "x24    28\n",
      "x25    22\n",
      "x26    36\n",
      "x27    30\n",
      "x28    35\n",
      "x29    30\n",
      "x30    30\n",
      "x31    39\n",
      "x32    31\n",
      "x33    41\n",
      "x34    41\n",
      "x35    30\n",
      "x36    27\n",
      "x37    23\n",
      "x38    31\n",
      "x39    23\n",
      "x40    36\n",
      "x41    40\n",
      "x42    26\n",
      "x43    37\n",
      "x44    40\n",
      "x45    29\n",
      "x46    31\n",
      "x47    37\n",
      "x48    32\n",
      "x49    32\n",
      "y       0\n",
      "dtype: int64\n",
      "0    95803\n",
      "1    64197\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_na = df.isna().sum()\n",
    "print(count_na)\n",
    "class_counts = df['y'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling the % in 'x32' by stripping the % and converting to float, then divide by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0000\n",
       "1        -0.0002\n",
       "2        -0.0001\n",
       "3         0.0001\n",
       "4         0.0001\n",
       "           ...  \n",
       "159995    0.0000\n",
       "159996   -0.0001\n",
       "159997   -0.0000\n",
       "159998   -0.0002\n",
       "159999    0.0002\n",
       "Name: x32, Length: 160000, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x32'] = df['x32'].str.replace('%', '')\n",
    "df['x32'] = pd.to_numeric(df['x32']) / 100\n",
    "df['x32']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling column 'x37' by stripping the $ and converting it to a float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\AppData\\Local\\Temp\\ipykernel_29884\\3516218164.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['x37'] = df['x37'].str.replace('$', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         1313.96\n",
       "1         1962.78\n",
       "2          430.47\n",
       "3        -2366.29\n",
       "4         -620.66\n",
       "           ...   \n",
       "159995    -891.96\n",
       "159996    1588.65\n",
       "159997     687.46\n",
       "159998     439.21\n",
       "159999   -1229.34\n",
       "Name: x37, Length: 160000, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x37'] = df['x37'].str.replace('$', '')\n",
    "df['x37'] = pd.to_numeric(df['x37'])\n",
    "df['x37']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing all of the missing data with either mean imputation for numerical or most frequent for category imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [f\"x{i}\" for i in range(50) if i not in [24, 29, 30]]\n",
    "cat_cols = [\"x24\", \"x29\", \"x30\"]\n",
    "#copy the target before doing the transform since it gets dropped\n",
    "y = df['y'].values\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='mean')  \n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_imputer', num_imputer, num_cols),\n",
    "        ('cat_imputer', cat_imputer, cat_cols)\n",
    "    ])\n",
    "\n",
    "df_imputed = pd.DataFrame(transformer.fit_transform(df), columns=num_cols+cat_cols)\n",
    "df_imputed.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0     0\n",
      "x1     0\n",
      "x2     0\n",
      "x3     0\n",
      "x4     0\n",
      "x5     0\n",
      "x6     0\n",
      "x7     0\n",
      "x8     0\n",
      "x9     0\n",
      "x10    0\n",
      "x11    0\n",
      "x12    0\n",
      "x13    0\n",
      "x14    0\n",
      "x15    0\n",
      "x16    0\n",
      "x17    0\n",
      "x18    0\n",
      "x19    0\n",
      "x20    0\n",
      "x21    0\n",
      "x22    0\n",
      "x23    0\n",
      "x25    0\n",
      "x26    0\n",
      "x27    0\n",
      "x28    0\n",
      "x31    0\n",
      "x32    0\n",
      "x33    0\n",
      "x34    0\n",
      "x35    0\n",
      "x36    0\n",
      "x37    0\n",
      "x38    0\n",
      "x39    0\n",
      "x40    0\n",
      "x41    0\n",
      "x42    0\n",
      "x43    0\n",
      "x44    0\n",
      "x45    0\n",
      "x46    0\n",
      "x47    0\n",
      "x48    0\n",
      "x49    0\n",
      "x24    0\n",
      "x29    0\n",
      "x30    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_na = df_imputed.isna().sum()\n",
    "print(count_na)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding the 'x24' that appears to be a continent, the x29 that is a month, and the x32 that is a weekday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>x24</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.00000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.00000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.00000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000</td>\n",
       "      <td>160000</td>\n",
       "      <td>160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>159975.000000</td>\n",
       "      <td>159976.000000</td>\n",
       "      <td>159963.000000</td>\n",
       "      <td>159964.000000</td>\n",
       "      <td>159975.000000</td>\n",
       "      <td>159964.000000</td>\n",
       "      <td>159975.00000</td>\n",
       "      <td>159974.000000</td>\n",
       "      <td>159980.00000</td>\n",
       "      <td>159971.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>159964.000000</td>\n",
       "      <td>159961.00000</td>\n",
       "      <td>159972.000000</td>\n",
       "      <td>159970.000000</td>\n",
       "      <td>159964.000000</td>\n",
       "      <td>159969.000000</td>\n",
       "      <td>159969.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>-1.150145</td>\n",
       "      <td>-0.024637</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>0.013582</td>\n",
       "      <td>-1.67067</td>\n",
       "      <td>-7.692795</td>\n",
       "      <td>-0.03054</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>-0.00625</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-12.755395</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.674224</td>\n",
       "      <td>asia</td>\n",
       "      <td>July</td>\n",
       "      <td>wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>138993</td>\n",
       "      <td>45599</td>\n",
       "      <td>101565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   x0             x1             x2             x3  \\\n",
       "count   160000.000000  160000.000000  160000.000000  160000.000000   \n",
       "unique  159975.000000  159976.000000  159963.000000  159964.000000   \n",
       "top         -0.001028       0.001358      -1.150145      -0.024637   \n",
       "freq        26.000000      25.000000      38.000000      37.000000   \n",
       "\n",
       "                   x4             x5            x6             x7  \\\n",
       "count   160000.000000  160000.000000  160000.00000  160000.000000   \n",
       "unique  159975.000000  159964.000000  159975.00000  159974.000000   \n",
       "top         -0.000549       0.013582      -1.67067      -7.692795   \n",
       "freq        26.000000      37.000000      26.00000      27.000000   \n",
       "\n",
       "                  x8             x9  ...            x43           x44  \\\n",
       "count   160000.00000  160000.000000  ...  160000.000000  160000.00000   \n",
       "unique  159980.00000  159971.000000  ...  159964.000000  159961.00000   \n",
       "top         -0.03054       0.005462  ...      -0.002091      -0.00625   \n",
       "freq        21.00000      30.000000  ...      37.000000      40.00000   \n",
       "\n",
       "                  x45            x46            x47            x48  \\\n",
       "count   160000.000000  160000.000000  160000.000000  160000.000000   \n",
       "unique  159972.000000  159970.000000  159964.000000  159969.000000   \n",
       "top          0.000885     -12.755395       0.028622      -0.000224   \n",
       "freq        29.000000      31.000000      37.000000      32.000000   \n",
       "\n",
       "                  x49     x24     x29        x30  \n",
       "count   160000.000000  160000  160000     160000  \n",
       "unique  159969.000000       3      12          5  \n",
       "top         -0.674224    asia    July  wednesday  \n",
       "freq        32.000000  138993   45599     101565  \n",
       "\n",
       "[4 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df_imputed, columns=['x24', 'x29', 'x30'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the data for a cross val predict like prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0               object\n",
       "x1               object\n",
       "x2               object\n",
       "x3               object\n",
       "x4               object\n",
       "                  ...  \n",
       "x30_friday        uint8\n",
       "x30_monday        uint8\n",
       "x30_thurday       uint8\n",
       "x30_tuesday       uint8\n",
       "x30_wednesday     uint8\n",
       "Length: 67, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the label values into y and the features into X\n",
    "\n",
    "X = df.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some data in a train and val split to perform the search of the best model\n",
    "#will circle back to using kfolds later\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1be7676b280>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 3, 7)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=16, max_value=512, step=16),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"])),\n",
    "            )\n",
    "        \n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-2, max_value=1, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adagrad(learning_rate=learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "build_model(kt.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a keras_tuner RandomSearch to tune the training process and optimize the Neural Network\n",
    "# https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    hyperband_iterations=6,\n",
    "    seed=1234,\n",
    "    directory='hp_tuning_2',\n",
    "    project_name='CaseStudy7_Run_2',\n",
    "    overwrite=False,\n",
    "    seed=1234\n",
    ")\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 7, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 0.01, 'conditions': [], 'min_value': 0.01, 'max_value': 1.0, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1524 Complete [00h 02m 25s]\n",
      "val_loss: 0.10673932731151581\n",
      "\n",
      "Best val_loss So Far: 0.09038040041923523\n",
      "Total elapsed time: 18h 31m 55s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "#train the DNN with a hyper parameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=50,\n",
    "             validation_data=(X_val, y_val),\n",
    "             callbacks=[es_callback])\n",
    "\n",
    "#get the best hyperparameters and store them in a var\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing a  K Fold split\n",
    "The best hyperparameters from the Hyperband tuning algorithm will be used to predict all 160,000 predictions, with models training on 143,999 datapoints using a 10 k fold split to where a model will train on that fold's training data, and then predictions made on the test set.  All test sets predictions will be concatenated into a flat array of predictions and scored for accuracy against the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 352)               276320    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               180736    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 336)               172368    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 240)               80880     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 192)               46272     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               49408     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 806,241\n",
      "Trainable params: 806,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.build(input_shape=(None, 28,28))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [ 16000  16001  16002 ... 159997 159998 159999]\n",
      "test: [    0     1     2 ... 15997 15998 15999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [16000 16001 16002 ... 31997 31998 31999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [32000 32001 32002 ... 47997 47998 47999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [48000 48001 48002 ... 63997 63998 63999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [64000 64001 64002 ... 79997 79998 79999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [80000 80001 80002 ... 95997 95998 95999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [ 96000  96001  96002 ... 111997 111998 111999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [112000 112001 112002 ... 127997 127998 127999]\n",
      "train: [     0      1      2 ... 159997 159998 159999]\n",
      "test: [128000 128001 128002 ... 143997 143998 143999]\n",
      "train: [     0      1      2 ... 143997 143998 143999]\n",
      "test: [144000 144001 144002 ... 159997 159998 159999]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "indices = kf.split(X,y)\n",
    "for train_index, test_index in indices:\n",
    "    print(f\"train: {train_index}\")\n",
    "    print(f\"test: {test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback_final = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.2775 - accuracy: 0.8826 - val_loss: 0.1639 - val_accuracy: 0.9419\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1354 - accuracy: 0.9517 - val_loss: 0.1157 - val_accuracy: 0.9609\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1069 - accuracy: 0.9643 - val_loss: 0.1035 - val_accuracy: 0.9664\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0918 - accuracy: 0.9700 - val_loss: 0.1042 - val_accuracy: 0.9660\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0805 - accuracy: 0.9737 - val_loss: 0.1053 - val_accuracy: 0.9658\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0720 - accuracy: 0.9772 - val_loss: 0.0982 - val_accuracy: 0.9685\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0633 - accuracy: 0.9806 - val_loss: 0.0965 - val_accuracy: 0.9696\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0572 - accuracy: 0.9824 - val_loss: 0.0938 - val_accuracy: 0.9711\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0511 - accuracy: 0.9848 - val_loss: 0.0969 - val_accuracy: 0.9709\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 0.1029 - val_accuracy: 0.9684\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0397 - accuracy: 0.9885 - val_loss: 0.1112 - val_accuracy: 0.9675\n",
      "500/500 [==============================] - 0s 734us/step\n",
      "Iteration 1\n",
      "Accuracy 0.96375\n",
      "Precision:  0.9505511328842621\n",
      "Recall:  0.9602536343952985\n",
      "F1 Score:  0.9553777504231421\n",
      "Confusion Matrix: \n",
      " [[9211  323]\n",
      " [ 257 6209]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.2734 - accuracy: 0.8837 - val_loss: 0.1607 - val_accuracy: 0.9411\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1338 - accuracy: 0.9522 - val_loss: 0.1397 - val_accuracy: 0.9519\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1073 - accuracy: 0.9636 - val_loss: 0.1088 - val_accuracy: 0.9642\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0917 - accuracy: 0.9697 - val_loss: 0.1036 - val_accuracy: 0.9649\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0801 - accuracy: 0.9740 - val_loss: 0.1011 - val_accuracy: 0.9679\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0710 - accuracy: 0.9773 - val_loss: 0.1065 - val_accuracy: 0.9657\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0641 - accuracy: 0.9797 - val_loss: 0.0994 - val_accuracy: 0.9688\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0563 - accuracy: 0.9828 - val_loss: 0.0999 - val_accuracy: 0.9697\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0497 - accuracy: 0.9851 - val_loss: 0.1086 - val_accuracy: 0.9671\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.1024 - val_accuracy: 0.9701\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.1098 - val_accuracy: 0.9698\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0341 - accuracy: 0.9899 - val_loss: 0.1205 - val_accuracy: 0.9669\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0284 - accuracy: 0.9918 - val_loss: 0.1198 - val_accuracy: 0.9694\n",
      "500/500 [==============================] - 0s 699us/step\n",
      "Iteration 2\n",
      "Accuracy 0.9678125\n",
      "Precision:  0.9678804261408809\n",
      "Recall:  0.95109375\n",
      "F1 Score:  0.9594136653794625\n",
      "Confusion Matrix: \n",
      " [[9398  202]\n",
      " [ 313 6087]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.2752 - accuracy: 0.8821 - val_loss: 0.1556 - val_accuracy: 0.9441\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1357 - accuracy: 0.9514 - val_loss: 0.1272 - val_accuracy: 0.9567\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.1077 - accuracy: 0.9636 - val_loss: 0.1077 - val_accuracy: 0.9650\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0920 - accuracy: 0.9697 - val_loss: 0.1057 - val_accuracy: 0.9644\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0798 - accuracy: 0.9745 - val_loss: 0.1031 - val_accuracy: 0.9681\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0718 - accuracy: 0.9775 - val_loss: 0.0984 - val_accuracy: 0.9694\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0637 - accuracy: 0.9799 - val_loss: 0.1025 - val_accuracy: 0.9681\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0558 - accuracy: 0.9832 - val_loss: 0.1069 - val_accuracy: 0.9663\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0497 - accuracy: 0.9855 - val_loss: 0.1048 - val_accuracy: 0.9696\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0444 - accuracy: 0.9869 - val_loss: 0.1073 - val_accuracy: 0.9686\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0398 - accuracy: 0.9884 - val_loss: 0.1131 - val_accuracy: 0.9681\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.1128 - val_accuracy: 0.9689\n",
      "500/500 [==============================] - 0s 755us/step\n",
      "Iteration 3\n",
      "Accuracy 0.9708125\n",
      "Precision:  0.9633323105247008\n",
      "Recall:  0.9649608114338405\n",
      "F1 Score:  0.9641458733205375\n",
      "Confusion Matrix: \n",
      " [[9254  239]\n",
      " [ 228 6279]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.2758 - accuracy: 0.8827 - val_loss: 0.1712 - val_accuracy: 0.9367\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1361 - accuracy: 0.9519 - val_loss: 0.1258 - val_accuracy: 0.9566\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1083 - accuracy: 0.9630 - val_loss: 0.1155 - val_accuracy: 0.9623\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0923 - accuracy: 0.9696 - val_loss: 0.1051 - val_accuracy: 0.9664\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0821 - accuracy: 0.9735 - val_loss: 0.1027 - val_accuracy: 0.9667\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0725 - accuracy: 0.9772 - val_loss: 0.1032 - val_accuracy: 0.9671\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0641 - accuracy: 0.9803 - val_loss: 0.1024 - val_accuracy: 0.9693\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0574 - accuracy: 0.9826 - val_loss: 0.1074 - val_accuracy: 0.9679\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0506 - accuracy: 0.9852 - val_loss: 0.1058 - val_accuracy: 0.9688\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.1063 - val_accuracy: 0.9700\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0404 - accuracy: 0.9884 - val_loss: 0.1069 - val_accuracy: 0.9686\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0353 - accuracy: 0.9899 - val_loss: 0.1116 - val_accuracy: 0.9709\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.1130 - val_accuracy: 0.9711\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.1250 - val_accuracy: 0.9690\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0243 - accuracy: 0.9930 - val_loss: 0.1303 - val_accuracy: 0.9688\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.1463 - val_accuracy: 0.9675\n",
      "500/500 [==============================] - 0s 802us/step\n",
      "Iteration 4\n",
      "Accuracy 0.967125\n",
      "Precision:  0.9627426424546024\n",
      "Recall:  0.9552656104380243\n",
      "F1 Score:  0.9589895524715422\n",
      "Confusion Matrix: \n",
      " [[9324  238]\n",
      " [ 288 6150]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.2767 - accuracy: 0.8811 - val_loss: 0.1640 - val_accuracy: 0.9405\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.1366 - accuracy: 0.9516 - val_loss: 0.1259 - val_accuracy: 0.9553\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1079 - accuracy: 0.9637 - val_loss: 0.1124 - val_accuracy: 0.9619\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0926 - accuracy: 0.9693 - val_loss: 0.1053 - val_accuracy: 0.9651\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0812 - accuracy: 0.9734 - val_loss: 0.1025 - val_accuracy: 0.9669\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0722 - accuracy: 0.9769 - val_loss: 0.1010 - val_accuracy: 0.9666\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0645 - accuracy: 0.9802 - val_loss: 0.0953 - val_accuracy: 0.9705\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.1009 - val_accuracy: 0.9694\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0508 - accuracy: 0.9846 - val_loss: 0.1019 - val_accuracy: 0.9699\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0456 - accuracy: 0.9865 - val_loss: 0.1055 - val_accuracy: 0.9690\n",
      "500/500 [==============================] - 0s 669us/step\n",
      "Iteration 5\n",
      "Accuracy 0.969625\n",
      "Precision:  0.9594656840165822\n",
      "Recall:  0.9656930922577655\n",
      "F1 Score:  0.9625693160813308\n",
      "Confusion Matrix: \n",
      " [[9265  264]\n",
      " [ 222 6249]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.2730 - accuracy: 0.8841 - val_loss: 0.1665 - val_accuracy: 0.9402\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.1341 - accuracy: 0.9527 - val_loss: 0.1218 - val_accuracy: 0.9579\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.1058 - accuracy: 0.9643 - val_loss: 0.1124 - val_accuracy: 0.9627\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0911 - accuracy: 0.9699 - val_loss: 0.1050 - val_accuracy: 0.9651\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0803 - accuracy: 0.9741 - val_loss: 0.1089 - val_accuracy: 0.9648\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0722 - accuracy: 0.9771 - val_loss: 0.1033 - val_accuracy: 0.9669\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0637 - accuracy: 0.9800 - val_loss: 0.0974 - val_accuracy: 0.9704\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0574 - accuracy: 0.9825 - val_loss: 0.1032 - val_accuracy: 0.9678\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.1005 - val_accuracy: 0.9701\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0450 - accuracy: 0.9865 - val_loss: 0.1086 - val_accuracy: 0.9686\n",
      "500/500 [==============================] - 0s 728us/step\n",
      "Iteration 6\n",
      "Accuracy 0.9685\n",
      "Precision:  0.9629337539432177\n",
      "Recall:  0.9577973015374961\n",
      "F1 Score:  0.9603586597451628\n",
      "Confusion Matrix: \n",
      " [[9391  235]\n",
      " [ 269 6105]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.2776 - accuracy: 0.8823 - val_loss: 0.1509 - val_accuracy: 0.9462\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1335 - accuracy: 0.9524 - val_loss: 0.1222 - val_accuracy: 0.9598\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1069 - accuracy: 0.9637 - val_loss: 0.1084 - val_accuracy: 0.9644\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0912 - accuracy: 0.9700 - val_loss: 0.1147 - val_accuracy: 0.9631\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0806 - accuracy: 0.9740 - val_loss: 0.0981 - val_accuracy: 0.9682\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0724 - accuracy: 0.9769 - val_loss: 0.1023 - val_accuracy: 0.9659\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0644 - accuracy: 0.9798 - val_loss: 0.0971 - val_accuracy: 0.9696\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 0.0998 - val_accuracy: 0.9698\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0503 - accuracy: 0.9852 - val_loss: 0.1015 - val_accuracy: 0.9690\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0450 - accuracy: 0.9870 - val_loss: 0.1028 - val_accuracy: 0.9708\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0396 - accuracy: 0.9886 - val_loss: 0.1141 - val_accuracy: 0.9686\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0363 - accuracy: 0.9896 - val_loss: 0.1089 - val_accuracy: 0.9701\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0305 - accuracy: 0.9913 - val_loss: 0.1122 - val_accuracy: 0.9720\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 0.1270 - val_accuracy: 0.9694\n",
      "Epoch 15/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.1293 - val_accuracy: 0.9699\n",
      "Epoch 16/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.1471 - val_accuracy: 0.9674\n",
      "500/500 [==============================] - 1s 947us/step\n",
      "Iteration 7\n",
      "Accuracy 0.9674375\n",
      "Precision:  0.9574299730970091\n",
      "Recall:  0.9600126943827356\n",
      "F1 Score:  0.9587195943269154\n",
      "Confusion Matrix: \n",
      " [[9429  269]\n",
      " [ 252 6050]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.2751 - accuracy: 0.8825 - val_loss: 0.1612 - val_accuracy: 0.9431\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.1351 - accuracy: 0.9525 - val_loss: 0.1243 - val_accuracy: 0.9579\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1071 - accuracy: 0.9636 - val_loss: 0.1151 - val_accuracy: 0.9605\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0928 - accuracy: 0.9692 - val_loss: 0.1080 - val_accuracy: 0.9662\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0814 - accuracy: 0.9735 - val_loss: 0.0999 - val_accuracy: 0.9691\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0718 - accuracy: 0.9769 - val_loss: 0.0996 - val_accuracy: 0.9685\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0649 - accuracy: 0.9793 - val_loss: 0.1116 - val_accuracy: 0.9654\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0575 - accuracy: 0.9822 - val_loss: 0.1001 - val_accuracy: 0.9690\n",
      "500/500 [==============================] - 0s 841us/step\n",
      "Iteration 8\n",
      "Accuracy 0.967375\n",
      "Precision:  0.9636277751535192\n",
      "Recall:  0.9546092653252223\n",
      "F1 Score:  0.9590973201692525\n",
      "Confusion Matrix: \n",
      " [[9358  231]\n",
      " [ 291 6120]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.2790 - accuracy: 0.8809 - val_loss: 0.1573 - val_accuracy: 0.9429\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1375 - accuracy: 0.9510 - val_loss: 0.1289 - val_accuracy: 0.9541\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1084 - accuracy: 0.9631 - val_loss: 0.1147 - val_accuracy: 0.9612\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0931 - accuracy: 0.9690 - val_loss: 0.1079 - val_accuracy: 0.9650\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0825 - accuracy: 0.9738 - val_loss: 0.1035 - val_accuracy: 0.9661\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0731 - accuracy: 0.9772 - val_loss: 0.1008 - val_accuracy: 0.9670\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0647 - accuracy: 0.9801 - val_loss: 0.1060 - val_accuracy: 0.9663\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0583 - accuracy: 0.9820 - val_loss: 0.1006 - val_accuracy: 0.9691\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0517 - accuracy: 0.9846 - val_loss: 0.1061 - val_accuracy: 0.9673\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0455 - accuracy: 0.9865 - val_loss: 0.1084 - val_accuracy: 0.9687\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0402 - accuracy: 0.9884 - val_loss: 0.1040 - val_accuracy: 0.9710\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0347 - accuracy: 0.9899 - val_loss: 0.1131 - val_accuracy: 0.9690\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.0303 - accuracy: 0.9914 - val_loss: 0.1221 - val_accuracy: 0.9683\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.1232 - val_accuracy: 0.9692\n",
      "500/500 [==============================] - 0s 756us/step\n",
      "Iteration 9\n",
      "Accuracy 0.9673125\n",
      "Precision:  0.9621164683782092\n",
      "Recall:  0.9562782013381048\n",
      "F1 Score:  0.9591884510339445\n",
      "Confusion Matrix: \n",
      " [[9331  242]\n",
      " [ 281 6146]]\n",
      "Epoch 1/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.2716 - accuracy: 0.8852 - val_loss: 0.1540 - val_accuracy: 0.9434\n",
      "Epoch 2/100\n",
      "3825/3825 [==============================] - 7s 2ms/step - loss: 0.1344 - accuracy: 0.9525 - val_loss: 0.1187 - val_accuracy: 0.9594\n",
      "Epoch 3/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.1076 - accuracy: 0.9632 - val_loss: 0.1113 - val_accuracy: 0.9631\n",
      "Epoch 4/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0911 - accuracy: 0.9699 - val_loss: 0.1061 - val_accuracy: 0.9651\n",
      "Epoch 5/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0810 - accuracy: 0.9735 - val_loss: 0.0961 - val_accuracy: 0.9686\n",
      "Epoch 6/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0717 - accuracy: 0.9772 - val_loss: 0.1027 - val_accuracy: 0.9673\n",
      "Epoch 7/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0647 - accuracy: 0.9796 - val_loss: 0.0972 - val_accuracy: 0.9693\n",
      "Epoch 8/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0569 - accuracy: 0.9824 - val_loss: 0.1054 - val_accuracy: 0.9670\n",
      "Epoch 9/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.1004 - val_accuracy: 0.9703\n",
      "Epoch 10/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 0.1065 - val_accuracy: 0.9681\n",
      "Epoch 11/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0387 - accuracy: 0.9888 - val_loss: 0.1014 - val_accuracy: 0.9707\n",
      "Epoch 12/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 0.1104 - val_accuracy: 0.9694\n",
      "Epoch 13/100\n",
      "3825/3825 [==============================] - 8s 2ms/step - loss: 0.0307 - accuracy: 0.9913 - val_loss: 0.1131 - val_accuracy: 0.9697\n",
      "Epoch 14/100\n",
      "3825/3825 [==============================] - 9s 2ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 0.1175 - val_accuracy: 0.9689\n",
      "500/500 [==============================] - 0s 768us/step\n",
      "Iteration 10\n",
      "Accuracy 0.9680625\n",
      "Precision:  0.9565891472868217\n",
      "Recall:  0.9639118887673801\n",
      "F1 Score:  0.9602365574663451\n",
      "Confusion Matrix: \n",
      " [[9319  280]\n",
      " [ 231 6170]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = []\n",
    "predictions = []\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    best_model = tuner.hypermodel.build(best_hps) #have to create a new instance of the model to ensure  it doesn't reload anything that it was previously trained on\n",
    "    X_train_val, X_test = X[train_index], X[test_index]\n",
    "    y_train_val, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.15, random_state=1234)\n",
    "    best_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[es_callback_final])\n",
    "    y_prob = best_model.predict(X_test)\n",
    "    y_pred = (y_prob > 0.5).astype(\"int32\")\n",
    "    probabilities.append(y_prob)\n",
    "    predictions.append(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Iteration {i}\")\n",
    "    print(f\"Accuracy {accuracy}\")\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"Confusion Matrix: \\n\", confusion)\n",
    "    i = i+1\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Scoring of the Neural Network Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.96778125\n",
      "Precision:  0.9606322556484833\n",
      "Recall:  0.9590011994329953\n",
      "F1 Score:  0.9598160346104376\n",
      "Confusion Matrix: \n",
      " [[93280  2523]\n",
      " [ 2632 61565]]\n",
      "Final Cost: $ 647,100.00\n"
     ]
    }
   ],
   "source": [
    "full_predictions = np.concatenate(predictions)\n",
    "accuracy = accuracy_score(y, full_predictions)\n",
    "precision = precision_score(y, full_predictions)\n",
    "recall = recall_score(y, full_predictions)\n",
    "f1 = f1_score(y, full_predictions)\n",
    "confusion = confusion_matrix(y, full_predictions)\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"Confusion Matrix: \\n\", confusion)\n",
    "cost = (confusion[0,1] * 100) + (confusion[1,0]*150) \n",
    "print(f\"Final Cost: $ {'{:,.2f}'.format(cost)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting for the higher cost of a FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.96656875\n",
      "Precision:  0.9503489653483531\n",
      "Recall:  0.9672103057775285\n",
      "F1 Score:  0.958705503616839\n",
      "Confusion Matrix: \n",
      " [[92559  3244]\n",
      " [ 2105 62092]]\n",
      "Final Cost: $ 640,150.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "full_probs = np.concatenate(probabilities)\n",
    "full_predictions = (full_probs > 0.315).astype(\"int32\")\n",
    "accuracy = accuracy_score(y, full_predictions)\n",
    "precision = precision_score(y, full_predictions)\n",
    "recall = recall_score(y, full_predictions)\n",
    "f1 = f1_score(y, full_predictions)\n",
    "confusion = confusion_matrix(y, full_predictions)\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"Confusion Matrix: \\n\", confusion)\n",
    "cost = (confusion[0,1] * 100) + (confusion[1,0]*150) \n",
    "print(f\"Final Cost: $ {'{:,.2f}'.format(cost)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 6, 'units_0': 352, 'activation': 'tanh', 'units_1': 512, 'units_2': 336, 'dropout': False, 'lr': 0.048868576203834016, 'units_3': 240, 'units_4': 192, 'units_5': 256, 'units_6': 112, 'tuner/epochs': 34, 'tuner/initial_epoch': 12, 'tuner/bracket': 3, 'tuner/round': 2, 'tuner/trial_id': '0697'}\n"
     ]
    }
   ],
   "source": [
    "print(best_hps.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
